Modeling matter: atomic-scale Lindhard
--------------------------------------
We'd all love an atomic-scale theory of how energy deposition is partitioned into electron and phonon systems - but it's hard because the unit cell you'd have to use for DFT is way beyond what computers can do in a year.

Some of the folks at LBNL and also England are making inroads by stitching together DFT methods with ... other, faster methods.  We should work with them, apply the methods to our detectors, and compare to measured calibration data!


Modeling matter: first steps
----------------------------
Historically, when we imagine a dark matter particle interacting in our detector, we pretend like the nucleus is a free particle floating in a vacuum.  This is a really good approximation if the energy transfer is large (say, 1 keV) because the scale of atomic binding energy is on the order of 10 eV.  But the dark matter community wants more sensitive experiments and drives hard to look at smaller and smaller energy transfers (CDMS recently published a paper that looked at energy transfers as small as 56 eV).  And it turns out we don't really understand energy transfer at these low-energy scales.

So that's exciting!

As it turns out, chemists have been interested in understanding how atoms move for a very long time - protein folding is a classic example.  They combine an accurate description of the electric field of an atom with F = ma (or sometimes the quantum mechanical version of that) and ... watch how the atoms move.  Which is exactly what we'd like to do.

The specific work I have in mind here is to adapt an instructional analysis on water to use the open-source NAMD code.  The downside is that this isn't immediately related to the CDMS dark matter search.  But it's a nice, finite project that gives you a chance to use electrostatics, electrodynamics, and quantum mechanics together to predict some properties of water.  And if you enjoy this work, an obvious second project is to do something similar but for germanium.


Signal to noise
---------------
When something interacts in our detector, it's only useful to us if we know about it.  So we set our detector up with sensors, and then the detector can tell us when something happens.

Then our job becomes one of translation: using only the signals from the detector, we need to determine what physics happened.

We have good ways of doing this, but I wonder if we could do even better by using all the signals from a detector, simulatneously.  (Right now we use them seperately.)  Specifically, I wonder if non-negative matrix factorization methods might give us a better signal-to-noise ratio.

This is a fun, highly math-oriented project that would involve lots of looking at original data, comparing to current algorithms, and thinking about the maximum amount of information we can get out of our signals.


Was that two hits or one? (Parker Pyle currently working on this)
-----------------------------------------------------------------
Surprisingly, calibrating the energy scale of our detectors is a real challenge.  Lots of standard calibration sources emit gammas or betas and these predominantly interact with the *electrons* in our detectors.  But we expect dark matter to overwhelmingly interact with the *nuclei* in our detectors.  

So ... what can we use to calibrate energy transfers to nuclei in our detectors?  Neutrons!

Except that - unlike gammas - it's hard to get neutrons that are all exactly the same energy.  So then we tie ourselves into knots trying to figure out how to use neutrons to calibrate despite their uncooperative nature.

I've actually got several projects related to this, but the one that immediately comes to mind is looking at some existing data to see if we can find a way to identify events where a neutron interacted in a detector many times, rather than only once.  (Low energy neutrons have a path length on the order of cm and tend to interact several times in our detectors, significanly complicating calibration analysis.)

This analysis is likely to be really fun at first - you'd spend a lot of time looking directly at detector signals and thinking about the physics that creates them.  But identifying events with multiple interactions is not gauranteed to be possible.  So the result of this analysis could well be "it would be super awesome to be able to distinguish multiple-interaction events but I have conclusively shown that this is not possible with CDMS detectors".  

If calibration sounds interesting to you but you're not keen on bitter disappointment, let me know and I can fill you in on some alternative calibration projects that, while not as signal-oriented as this one, aren't null-result territory.


Miscellany
----------
* build a small cosmic-ray detector!
* help fix unnecessary exclusion: make our detector-control software accessible to people with low or no vision
* solve a problem that plagues the entire physics community: develop a prototype data reader and writer that needs only a user-supplied description of the data to read and write files
* how we process the data now is fine but what if we could do it better!?: measure the speed of the algorithms we use to process CDMS data; adapt them for use on a GPU
* why so slow, mhttpd: one of the core pieces of our DAQ software is sometimes incredibly slow.  Find out why, and fix it.
* Make it easier to process CDMS data: Develop a Nix expression that will install the version of ROOT needed by CDMS software.    